{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import utils\n",
    "from GP_Beta_cal import GP_Beta\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the boston dataset and split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_raw, y_raw) = sklearn.datasets.load_boston(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x_raw, y_raw.ravel(),\n",
    "                                                                            test_size=0.25, shuffle=True)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple dense neural net, and obtain its prediction (mean and std) using MC dropout.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = utils.get_mdl(x_train, y_train, 'olr') # change 'olr' to 'deep' / 'br' / 'gp' for other base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a calibration set by collecting model prediction (mean and std) using MC dropout.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_cal, sigma_cal = utils.get_prediction(x_train, base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the bins edges to calculate the corresponding PDF / CDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t_test = 1024\n",
    "\n",
    "t_list_test = numpy.linspace(numpy.min(mu_cal) - 16.0 * numpy.max(sigma_cal),\n",
    "                             numpy.max(mu_cal) + 16.0 * numpy.max(sigma_cal),\n",
    "                             n_t_test).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the GP-Beta calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.36 -1.15  1.1   1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.00e+00 1.00e-03 9.99e-01 1.00e-03 1.00e+00 1.00e-03], shape=(6,), dtype=float64)\n",
      "Batch: 0, optimiser: adam, Loss: 3.07376565941576\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hs12248\\Google Drive\\Workspace\\Github\\DistCal\\GP_Beta_cal.py:624: UserWarning: Attempting to set identical bottom == top == 3.07376565941576 results in singular transformations; automatically expanding.\n",
      "  matplotlib.pyplot.ylim([numpy.min(batch_L), numpy.median(batch_L)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.1   1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 1, optimiser: adam, Loss: 3.07286883775586\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.1   1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 2, optimiser: adam, Loss: 3.0706425291690413\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.1   1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 3, optimiser: adam, Loss: 3.06906560271751\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.1   1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 4, optimiser: adam, Loss: 3.0689518918782888\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.09  1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 5, optimiser: adam, Loss: 3.0659652800319437\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    1.    1.35 -1.15  1.09  1.    1.    1.  ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0.], shape=(6,), dtype=float64)\n",
      "Batch: 6, optimiser: adam, Loss: 3.0635428552234774\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.15  1.09  1.01  1.    0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 7, optimiser: adam, Loss: 3.063038689225842\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.15  1.09  1.01  1.    0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 8, optimiser: adam, Loss: 3.061537311922491\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  1.    0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 9, optimiser: adam, Loss: 3.061827858660129\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  1.    0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 10, optimiser: adam, Loss: 3.0598641910540163\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 11, optimiser: adam, Loss: 3.056622101539398\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 12, optimiser: adam, Loss: 3.056041660324017\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  1.    0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.   1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 13, optimiser: adam, Loss: 3.0551375779441314\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 14, optimiser: adam, Loss: 3.0536012743284475\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 15, optimiser: adam, Loss: 3.051412254385494\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 16, optimiser: adam, Loss: 3.0503363417622587\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 17, optimiser: adam, Loss: 3.0503809852890282\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 18, optimiser: adam, Loss: 3.047229323868932\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.35 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 19, optimiser: adam, Loss: 3.0462057406137393\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 20, optimiser: adam, Loss: 3.0468395188355983\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 21, optimiser: adam, Loss: 3.0432287997189147\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 22, optimiser: adam, Loss: 3.0424207409936965\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 23, optimiser: adam, Loss: 3.0427214897709174\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.09  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 24, optimiser: adam, Loss: 3.0399634074971313\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.08  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 25, optimiser: adam, Loss: 3.0386262690983386\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.99  1.34 -1.14  1.08  1.01  0.99  0.99], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.01 0.01 0.99 0.01 1.01 0.01], shape=(6,), dtype=float64)\n",
      "Batch: 26, optimiser: adam, Loss: 3.0384275031855053\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.14  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 27, optimiser: adam, Loss: 3.034835519938187\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.14  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 28, optimiser: adam, Loss: 3.033954094872173\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 29, optimiser: adam, Loss: 3.0344794634988603\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 30, optimiser: adam, Loss: 3.031295595553052\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 31, optimiser: adam, Loss: 3.031400458333959\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 32, optimiser: adam, Loss: 3.030506401300381\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.03]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 33, optimiser: adam, Loss: 3.0273161073343884\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.03]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 34, optimiser: adam, Loss: 3.0285792612738938\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.03]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 35, optimiser: adam, Loss: 3.0249720757553398\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 36, optimiser: adam, Loss: 3.024481300973786\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.34 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 37, optimiser: adam, Loss: 3.0237832955427058\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.07 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 38, optimiser: adam, Loss: 3.0214515575272807\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 39, optimiser: adam, Loss: 3.0222759435583475\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.08  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 40, optimiser: adam, Loss: 3.019250961133872\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.07  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 41, optimiser: adam, Loss: 3.0179606306335787\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.07  1.02  0.99  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 42, optimiser: adam, Loss: 3.0164452419111702\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.02]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.98  1.33 -1.13  1.07  1.02  0.98  0.98], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.02 0.02 0.98 0.01 1.02 0.02], shape=(6,), dtype=float64)\n",
      "Batch: 43, optimiser: adam, Loss: 3.0145646672158892\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.13  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.01 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 44, optimiser: adam, Loss: 3.014440254406989\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.01 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 45, optimiser: adam, Loss: 3.0133650687288367\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.06 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 46, optimiser: adam, Loss: 3.0115242044921904\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 47, optimiser: adam, Loss: 3.0104304865760403\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 48, optimiser: adam, Loss: 3.0082115207444087\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 49, optimiser: adam, Loss: 3.0069558816815896\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 50, optimiser: adam, Loss: 3.00658845057795\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 51, optimiser: adam, Loss: 3.0052735645174744\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.01]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.33 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 52, optimiser: adam, Loss: 3.0019958437721637\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.05 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.32 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 53, optimiser: adam, Loss: 3.001445851821666\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.32 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 54, optimiser: adam, Loss: 3.0005958527249597\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.32 -1.12  1.07  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 55, optimiser: adam, Loss: 2.9999167573368397\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.32 -1.12  1.06  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 56, optimiser: adam, Loss: 2.9985412006509486\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.97  1.32 -1.12  1.06  1.03  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.03 0.03 0.97 0.02 1.03 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 57, optimiser: adam, Loss: 2.9976951591186807\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.12  1.06  1.04  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 58, optimiser: adam, Loss: 2.997197370449371\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.04 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.97], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 59, optimiser: adam, Loss: 2.9955223694138517\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 3.  ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.03], shape=(6,), dtype=float64)\n",
      "Batch: 60, optimiser: adam, Loss: 2.993327517312256\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 61, optimiser: adam, Loss: 2.993155515142867\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 62, optimiser: adam, Loss: 2.9904506805395212\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.02 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 63, optimiser: adam, Loss: 2.9902734589405466\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 64, optimiser: adam, Loss: 2.9883254110272217\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.32 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 65, optimiser: adam, Loss: 2.9871495759750526\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.31 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 66, optimiser: adam, Loss: 2.987546013232032\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.03 2.99]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.31 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 67, optimiser: adam, Loss: 2.984271233024738\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.31 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 68, optimiser: adam, Loss: 2.984414533341168\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.96  1.31 -1.11  1.06  1.04  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.04 0.04 0.96 0.03 1.04 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 69, optimiser: adam, Loss: 2.9843829650974505\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.95  1.31 -1.11  1.06  1.05  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 70, optimiser: adam, Loss: 2.9834146047252266\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.95  1.31 -1.11  1.06  1.05  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 71, optimiser: adam, Loss: 2.9808583887880507\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.11  1.06  1.05  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 72, optimiser: adam, Loss: 2.9807376304836875\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.1   1.06  1.05  0.98  0.96], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 73, optimiser: adam, Loss: 2.978307636151958\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.1   1.05  1.05  0.98  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 74, optimiser: adam, Loss: 2.976737217816208\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.02 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.1   1.05  1.05  0.98  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 75, optimiser: adam, Loss: 2.9760528346561617\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.1   1.05  1.05  0.98  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 76, optimiser: adam, Loss: 2.975222135350993\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.98]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.31 -1.1   1.05  1.05  0.98  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 77, optimiser: adam, Loss: 2.9737172426861065\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.3  -1.1   1.05  1.05  0.98  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 78, optimiser: adam, Loss: 2.9740605851004482\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.3  -1.1   1.05  1.05  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 79, optimiser: adam, Loss: 2.9719228457856826\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.3  -1.1   1.05  1.05  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 80, optimiser: adam, Loss: 2.9710826391945706\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.95  1.3  -1.1   1.05  1.05  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.05 0.05 0.95 0.03 1.05 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 81, optimiser: adam, Loss: 2.971400296042588\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.1   1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.04 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 82, optimiser: adam, Loss: 2.9688216719434695\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.1   1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 83, optimiser: adam, Loss: 2.9680207054889514\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.01 2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.1   1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 84, optimiser: adam, Loss: 2.9672733859038325\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 85, optimiser: adam, Loss: 2.9663145782997518\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.97]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.04 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 86, optimiser: adam, Loss: 2.9645809379724746\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 87, optimiser: adam, Loss: 2.9647859961028646\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.3  -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 88, optimiser: adam, Loss: 2.9631292000791936\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.03 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 89, optimiser: adam, Loss: 2.9618463473046095\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.06  0.99  0.95], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.04 1.06 0.04], shape=(6,), dtype=float64)\n",
      "Batch: 90, optimiser: adam, Loss: 2.961741806056167\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.06  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.04 1.06 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 91, optimiser: adam, Loss: 2.9605720011084915\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[3.   2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.06  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.06 0.06 0.94 0.04 1.06 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 92, optimiser: adam, Loss: 2.9600876517811847\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 93, optimiser: adam, Loss: 2.9579228740232\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.94  1.29 -1.09  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 94, optimiser: adam, Loss: 2.9566005670692674\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.29 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 95, optimiser: adam, Loss: 2.9559484463713552\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.96]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.29 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 96, optimiser: adam, Loss: 2.954970169216934\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.29 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 97, optimiser: adam, Loss: 2.9545529026560775\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.29 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 98, optimiser: adam, Loss: 2.9527817740747255\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.99 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 99, optimiser: adam, Loss: 2.952919455407549\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 100, optimiser: adam, Loss: 2.950712217865524\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 101, optimiser: adam, Loss: 2.9502796257592854\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.07  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.07 0.07 0.93 0.04 1.07 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 102, optimiser: adam, Loss: 2.949231289133383\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.04 1.08 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 103, optimiser: adam, Loss: 2.9489935315324707\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.04 1.08 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 104, optimiser: adam, Loss: 2.9473775810885092\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.04 1.08 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 105, optimiser: adam, Loss: 2.9461643122345964\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 106, optimiser: adam, Loss: 2.9467756012695765\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.95]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 107, optimiser: adam, Loss: 2.943591993531287\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.28 -1.08  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.05], shape=(6,), dtype=float64)\n",
      "Batch: 108, optimiser: adam, Loss: 2.9431042791669833\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.98 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.27 -1.07  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 109, optimiser: adam, Loss: 2.943534474173169\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.27 -1.07  1.05  1.08  0.99  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 110, optimiser: adam, Loss: 2.94237082887778\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.27 -1.07  1.05  1.08  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 111, optimiser: adam, Loss: 2.940535546828837\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.27 -1.07  1.05  1.08  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.08 0.08 0.92 0.05 1.08 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 112, optimiser: adam, Loss: 2.9397065350579097\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.95  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 113, optimiser: adam, Loss: 2.9405971545646685\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 114, optimiser: adam, Loss: 2.9393524036513536\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 115, optimiser: adam, Loss: 2.9383741215173926\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 116, optimiser: adam, Loss: 2.93682794902976\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 117, optimiser: adam, Loss: 2.936060092285666\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.97 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.27 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 118, optimiser: adam, Loss: 2.93541550931865\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.94]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.26 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 119, optimiser: adam, Loss: 2.934023456307308\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.26 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 120, optimiser: adam, Loss: 2.9341773536086717\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.26 -1.07  1.05  1.09  1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.09 0.09 0.91 0.05 1.09 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 121, optimiser: adam, Loss: 2.9329874311198885\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.96  0.93  1.26 -1.07  1.05  1.1   1.    0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.05 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 122, optimiser: adam, Loss: 2.93124976417875\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.26 -1.07  1.05  1.1   1.    0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.05 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 123, optimiser: adam, Loss: 2.932253646076424\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.26 -1.07  1.05  1.1   1.    0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.05 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 124, optimiser: adam, Loss: 2.929862839222183\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.26 -1.06  1.05  1.1   1.    0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.05 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 125, optimiser: adam, Loss: 2.9292263492169344\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.26 -1.06  1.05  1.1   1.01  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 126, optimiser: adam, Loss: 2.928227071057185\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.26 -1.06  1.05  1.1   1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 127, optimiser: adam, Loss: 2.926027373054582\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.96 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.1   1.01  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 128, optimiser: adam, Loss: 2.9270235937217963\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.1   1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 129, optimiser: adam, Loss: 2.9275919019264163\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.93]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.1   1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.1  0.1  0.9  0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 130, optimiser: adam, Loss: 2.9249288450471203\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.11  1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 131, optimiser: adam, Loss: 2.924234507847132\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.11  1.01  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.1  0.06], shape=(6,), dtype=float64)\n",
      "Batch: 132, optimiser: adam, Loss: 2.9227868080736124\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.97  0.93  1.25 -1.06  1.05  1.11  1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 133, optimiser: adam, Loss: 2.9225594158459645\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.25 -1.06  1.05  1.11  1.01  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 134, optimiser: adam, Loss: 2.921584386535288\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.25 -1.06  1.05  1.11  1.01  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.06], shape=(6,), dtype=float64)\n",
      "Batch: 135, optimiser: adam, Loss: 2.919841140526787\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.25 -1.06  1.05  1.11  1.01  0.94], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 136, optimiser: adam, Loss: 2.9200494958418632\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.25 -1.06  1.05  1.11  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 137, optimiser: adam, Loss: 2.919187315945362\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.25 -1.05  1.05  1.11  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.06 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 138, optimiser: adam, Loss: 2.9181194481476003\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.95 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.24 -1.05  1.05  1.11  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.11 0.11 0.89 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 139, optimiser: adam, Loss: 2.9182905813034314\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.24 -1.05  1.04  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 140, optimiser: adam, Loss: 2.9153794735875707\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 141, optimiser: adam, Loss: 2.9151655598227033\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.92]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.98  0.93  1.24 -1.05  1.04  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 142, optimiser: adam, Loss: 2.9148091450108295\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 143, optimiser: adam, Loss: 2.9136812185109684\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 144, optimiser: adam, Loss: 2.912976764200127\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 145, optimiser: adam, Loss: 2.9114737188456594\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 146, optimiser: adam, Loss: 2.91186999554344\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 147, optimiser: adam, Loss: 2.9125314044179955\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.12  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 148, optimiser: adam, Loss: 2.910520237382141\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 149, optimiser: adam, Loss: 2.9094490501430244\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 150, optimiser: adam, Loss: 2.909393303927656\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.94 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.12  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 151, optimiser: adam, Loss: 2.909086442966207\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.24 -1.05  1.05  1.12  1.02  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 152, optimiser: adam, Loss: 2.9095828855681742\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.12  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.12 0.12 0.88 0.07 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 153, optimiser: adam, Loss: 2.910488033792932\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.11 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 154, optimiser: adam, Loss: 2.9095182939457827\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 155, optimiser: adam, Loss: 2.908867838262288\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 156, optimiser: adam, Loss: 2.9088230003553166\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 157, optimiser: adam, Loss: 2.906974027925236\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 0.99  0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 158, optimiser: adam, Loss: 2.9070171713096604\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 159, optimiser: adam, Loss: 2.9063276291892297\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.23 -1.05  1.05  1.13  1.03  0.93], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 160, optimiser: adam, Loss: 2.9062547906606238\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.23 -1.05  1.05  1.13  1.03  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.07], shape=(6,), dtype=float64)\n",
      "Batch: 161, optimiser: adam, Loss: 2.9054891326219234\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.93 2.91]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.23 -1.05  1.05  1.13  1.03  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 162, optimiser: adam, Loss: 2.904069075205606\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.13  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 163, optimiser: adam, Loss: 2.904076045483916\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 164, optimiser: adam, Loss: 2.90229269397555\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.13  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 165, optimiser: adam, Loss: 2.902805863010069\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 166, optimiser: adam, Loss: 2.9028273565259335\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.13  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 167, optimiser: adam, Loss: 2.902883372849586\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.13  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.13 0.13 0.87 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 168, optimiser: adam, Loss: 2.9035358370633477\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.12 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 169, optimiser: adam, Loss: 2.9031047668976915\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 170, optimiser: adam, Loss: 2.9018489940890917\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.    0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 171, optimiser: adam, Loss: 2.901286647842108\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.93  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.08 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 172, optimiser: adam, Loss: 2.900842180255762\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.93  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 173, optimiser: adam, Loss: 2.9002941564339566\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.92 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.93  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 174, optimiser: adam, Loss: 2.8981988179668208\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.05  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 175, optimiser: adam, Loss: 2.898750054273392\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.93  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 176, optimiser: adam, Loss: 2.9005564893089963\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 177, optimiser: adam, Loss: 2.897289418727089\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.93  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 178, optimiser: adam, Loss: 2.899964771329721\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.14  1.04  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 179, optimiser: adam, Loss: 2.898252097671279\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.14  1.04  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 180, optimiser: adam, Loss: 2.897373883619192\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.15  1.04  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 181, optimiser: adam, Loss: 2.8960003823876797\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.14  1.04  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 182, optimiser: adam, Loss: 2.8974144813633833\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.14  1.04  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.14 0.14 0.86 0.09 1.13 0.08], shape=(6,), dtype=float64)\n",
      "Batch: 183, optimiser: adam, Loss: 2.898070724550673\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.22 -1.04  1.05  1.15  1.04  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 184, optimiser: adam, Loss: 2.896503176150208\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.9 ]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 185, optimiser: adam, Loss: 2.8937043095678017\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.05  1.05  1.15  1.05  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 186, optimiser: adam, Loss: 2.894821033967528\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 187, optimiser: adam, Loss: 2.8958378633172597\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.05  1.05  1.15  1.05  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 188, optimiser: adam, Loss: 2.89435396931337\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 189, optimiser: adam, Loss: 2.893993449184533\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.05  1.05  1.15  1.05  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 190, optimiser: adam, Loss: 2.8949788376269243\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.01  0.94  1.21 -1.05  1.05  1.15  1.05  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 191, optimiser: adam, Loss: 2.8962543864158556\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.09 1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 192, optimiser: adam, Loss: 2.895283958941393\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.92], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 193, optimiser: adam, Loss: 2.893351138141204\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.91 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 194, optimiser: adam, Loss: 2.8944490972012256\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 195, optimiser: adam, Loss: 2.892718288556886\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 196, optimiser: adam, Loss: 2.8945591791284637\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 197, optimiser: adam, Loss: 2.892426984397108\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.05  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 198, optimiser: adam, Loss: 2.8922202184655896\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 199, optimiser: adam, Loss: 2.892505768414859\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.16  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 200, optimiser: adam, Loss: 2.890082715190658\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 201, optimiser: adam, Loss: 2.8910821512126126\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.15  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.15 0.15 0.85 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 202, optimiser: adam, Loss: 2.8921850824828503\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.21 -1.04  1.05  1.16  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.13 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 203, optimiser: adam, Loss: 2.8897802145002704\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 204, optimiser: adam, Loss: 2.890650826031319\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.2  -1.04  1.05  1.16  1.05  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 205, optimiser: adam, Loss: 2.889587304444239\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 206, optimiser: adam, Loss: 2.8893098366348493\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.09], shape=(6,), dtype=float64)\n",
      "Batch: 207, optimiser: adam, Loss: 2.8899704054422797\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.02  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 208, optimiser: adam, Loss: 2.8901344532079176\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 209, optimiser: adam, Loss: 2.887762184722573\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 210, optimiser: adam, Loss: 2.8869290982810414\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 211, optimiser: adam, Loss: 2.8900864402186155\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 212, optimiser: adam, Loss: 2.88791955042542\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 213, optimiser: adam, Loss: 2.887923025675412\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 214, optimiser: adam, Loss: 2.887788254602504\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 215, optimiser: adam, Loss: 2.8881342556097613\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 216, optimiser: adam, Loss: 2.888016541392598\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.9  2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 217, optimiser: adam, Loss: 2.8884041260079876\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 218, optimiser: adam, Loss: 2.8883491334074174\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 219, optimiser: adam, Loss: 2.888472028503809\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 220, optimiser: adam, Loss: 2.8888369881764446\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 221, optimiser: adam, Loss: 2.8876806942972864\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 222, optimiser: adam, Loss: 2.8872745011717416\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 223, optimiser: adam, Loss: 2.888673610722587\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 224, optimiser: adam, Loss: 2.887454416354349\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 225, optimiser: adam, Loss: 2.888040199749\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 226, optimiser: adam, Loss: 2.888183756599719\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 227, optimiser: adam, Loss: 2.888747604975167\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 228, optimiser: adam, Loss: 2.8884690529724946\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 229, optimiser: adam, Loss: 2.8866885403733127\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 230, optimiser: adam, Loss: 2.885630807729431\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 231, optimiser: adam, Loss: 2.8869679347349293\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 232, optimiser: adam, Loss: 2.886025471190725\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 233, optimiser: adam, Loss: 2.8863242218942573\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 234, optimiser: adam, Loss: 2.885553564274995\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.2  -1.04  1.05  1.16  1.06  0.91], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.16 0.16 0.84 0.1  1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 235, optimiser: adam, Loss: 2.886582669199066\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 236, optimiser: adam, Loss: 2.8851433058630014\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 237, optimiser: adam, Loss: 2.8853732912863768\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 238, optimiser: adam, Loss: 2.885209196069022\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 239, optimiser: adam, Loss: 2.885709411490516\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.89]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 240, optimiser: adam, Loss: 2.8840911547436283\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 241, optimiser: adam, Loss: 2.8858346312237706\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 242, optimiser: adam, Loss: 2.886143417774448\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 243, optimiser: adam, Loss: 2.88480393178203\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 244, optimiser: adam, Loss: 2.881898527897263\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 245, optimiser: adam, Loss: 2.8855215714801212\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 246, optimiser: adam, Loss: 2.884292560952552\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 247, optimiser: adam, Loss: 2.8838802188935784\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 248, optimiser: adam, Loss: 2.883974586855589\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 249, optimiser: adam, Loss: 2.884942342781681\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 250, optimiser: adam, Loss: 2.883362814722269\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 251, optimiser: adam, Loss: 2.8847842414006837\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 252, optimiser: adam, Loss: 2.8850058942796837\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.1 ], shape=(6,), dtype=float64)\n",
      "Batch: 253, optimiser: adam, Loss: 2.8825323360109447\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.03  0.94  1.19 -1.04  1.05  1.17  1.06  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 254, optimiser: adam, Loss: 2.8836181502836373\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 255, optimiser: adam, Loss: 2.882100092587487\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 256, optimiser: adam, Loss: 2.881670707398215\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 257, optimiser: adam, Loss: 2.8821270963219634\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 258, optimiser: adam, Loss: 2.8822601261550442\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 259, optimiser: adam, Loss: 2.883790907639835\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 260, optimiser: adam, Loss: 2.8808352635352\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 261, optimiser: adam, Loss: 2.8830228304087195\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.04  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 262, optimiser: adam, Loss: 2.881858542552705\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 263, optimiser: adam, Loss: 2.8824709074765047\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.04  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 264, optimiser: adam, Loss: 2.881697131010477\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 265, optimiser: adam, Loss: 2.88171209092385\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 266, optimiser: adam, Loss: 2.882833219863999\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 267, optimiser: adam, Loss: 2.882977515681126\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 268, optimiser: adam, Loss: 2.884033542412604\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 269, optimiser: adam, Loss: 2.8816396481071362\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 270, optimiser: adam, Loss: 2.881796440708138\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 271, optimiser: adam, Loss: 2.8823345863040104\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.89 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 272, optimiser: adam, Loss: 2.882448549454641\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 273, optimiser: adam, Loss: 2.882193534135348\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 274, optimiser: adam, Loss: 2.881157861583498\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 275, optimiser: adam, Loss: 2.8811785177050564\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 276, optimiser: adam, Loss: 2.8822252625690665\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 277, optimiser: adam, Loss: 2.8823704579150013\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 278, optimiser: adam, Loss: 2.882266138275552\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 279, optimiser: adam, Loss: 2.882179162505057\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 280, optimiser: adam, Loss: 2.8803599342722968\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 281, optimiser: adam, Loss: 2.8814813114031046\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 282, optimiser: adam, Loss: 2.8820781645075515\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 283, optimiser: adam, Loss: 2.8811386469834903\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 284, optimiser: adam, Loss: 2.880864396277986\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 285, optimiser: adam, Loss: 2.882758016739396\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 286, optimiser: adam, Loss: 2.8809256133357852\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 287, optimiser: adam, Loss: 2.8820181884789835\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 288, optimiser: adam, Loss: 2.8811341960307373\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 289, optimiser: adam, Loss: 2.8825102925424435\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 290, optimiser: adam, Loss: 2.8813793413875253\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 291, optimiser: adam, Loss: 2.881649396102069\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 292, optimiser: adam, Loss: 2.8811088045324436\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 293, optimiser: adam, Loss: 2.8807914241373735\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 294, optimiser: adam, Loss: 2.8812913458239247\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 295, optimiser: adam, Loss: 2.8808428906417034\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 296, optimiser: adam, Loss: 2.8804203500076904\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 297, optimiser: adam, Loss: 2.879934322449717\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 298, optimiser: adam, Loss: 2.8816723904630868\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 299, optimiser: adam, Loss: 2.880749103388283\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 300, optimiser: adam, Loss: 2.8814559487935414\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 301, optimiser: adam, Loss: 2.881130392081544\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 302, optimiser: adam, Loss: 2.880241715221276\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 303, optimiser: adam, Loss: 2.8805480903971943\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 304, optimiser: adam, Loss: 2.8812490095413015\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 305, optimiser: adam, Loss: 2.8817439206015694\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 306, optimiser: adam, Loss: 2.8804255793803897\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 307, optimiser: adam, Loss: 2.880349241305114\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 308, optimiser: adam, Loss: 2.8808016367713987\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 309, optimiser: adam, Loss: 2.8803720054557402\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 310, optimiser: adam, Loss: 2.8811873467384084\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 311, optimiser: adam, Loss: 2.8808846514474227\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 312, optimiser: adam, Loss: 2.881083754447966\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 313, optimiser: adam, Loss: 2.8803539905675777\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 314, optimiser: adam, Loss: 2.878988138194353\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 315, optimiser: adam, Loss: 2.8819183871219702\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 316, optimiser: adam, Loss: 2.8809376367807005\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 317, optimiser: adam, Loss: 2.880155378713273\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 318, optimiser: adam, Loss: 2.8810435315008585\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 319, optimiser: adam, Loss: 2.880798290211693\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 320, optimiser: adam, Loss: 2.880237901817528\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 321, optimiser: adam, Loss: 2.8815516888355446\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 322, optimiser: adam, Loss: 2.880803369304638\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 323, optimiser: adam, Loss: 2.8821706860848373\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.94  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.83 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 324, optimiser: adam, Loss: 2.8806410977065515\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 325, optimiser: adam, Loss: 2.8805742734779036\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 326, optimiser: adam, Loss: 2.8813059162960104\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 327, optimiser: adam, Loss: 2.881016131342163\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 328, optimiser: adam, Loss: 2.8816310844195323\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 329, optimiser: adam, Loss: 2.880986331167336\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 330, optimiser: adam, Loss: 2.8808265083273956\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 331, optimiser: adam, Loss: 2.8819321999961836\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.18 -1.04  1.05  1.18  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.18 0.18 0.82 0.11 1.15 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 332, optimiser: adam, Loss: 2.880015327866428\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 333, optimiser: adam, Loss: 2.880683017147944\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 334, optimiser: adam, Loss: 2.8812705210351903\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 335, optimiser: adam, Loss: 2.8811322672788124\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 336, optimiser: adam, Loss: 2.8809602306498725\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 337, optimiser: adam, Loss: 2.8796680777711314\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 338, optimiser: adam, Loss: 2.881620877056234\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 339, optimiser: adam, Loss: 2.881733929490167\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 340, optimiser: adam, Loss: 2.8802392761525284\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 341, optimiser: adam, Loss: 2.8802675748720317\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 342, optimiser: adam, Loss: 2.8808008514323866\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 343, optimiser: adam, Loss: 2.8825985903225084\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 344, optimiser: adam, Loss: 2.880742904531025\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 345, optimiser: adam, Loss: 2.8802070091510124\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n",
      "NaN in gradient.\n",
      "=============================================================================\n",
      "tf.Tensor([ 1.04  0.95  1.19 -1.04  1.05  1.17  1.07  0.9 ], shape=(8,), dtype=float64)\n",
      "tf.Tensor([1.17 0.17 0.83 0.11 1.14 0.11], shape=(6,), dtype=float64)\n",
      "Batch: 346, optimiser: adam, Loss: 2.880679179624881\n",
      "=============================================================================\n",
      "Previous And Recent Top Averaged Loss Is:\n",
      "[2.88 2.88]\n"
     ]
    }
   ],
   "source": [
    "n_u = 8 # number of induced points\n",
    "GP_Beta_mdl = GP_Beta()\n",
    "GP_Beta_mdl.fit(y_train, mu_cal, sigma_cal, n_u=n_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the isotonic quantile calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                   y_min=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_q, iso_q_hat = utils.get_iso_cal_table(y_train, mu_cal, sigma_cal)\n",
    "\n",
    "iso_mdl = IsotonicRegression(out_of_bounds='clip')\n",
    "\n",
    "iso_mdl.fit(iso_q, iso_q_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain base model prediction on the testing set, as well as predicted PDF and CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_base, sigma_base = utils.get_prediction(x_test, base_model)\n",
    "\n",
    "y_base = mu_base.ravel()\n",
    "\n",
    "q_base, s_base = utils.get_norm_q(mu_base.ravel(), sigma_base.ravel(), t_list_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply GP-Beta calibrator to get predicted target value, negtive log-likelihood, PDF and CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_gp, q_gp = GP_Beta_mdl.predict(t_list_test, mu_base, sigma_base)\n",
    "\n",
    "y_gp = utils.get_y_hat(t_list_test.ravel(), s_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply isotonic calibrator to get predicted target value, negtive log-likelihood, PDF and CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_iso = iso_mdl.predict(q_base.ravel()).reshape(numpy.shape(q_base))\n",
    "\n",
    "s_iso = numpy.diff(q_iso, axis=1) / \\\n",
    "        (t_list_test[0, 1:] - t_list_test[0, :-1]).ravel().reshape(1, -1).repeat(len(y_test), axis=0)\n",
    "\n",
    "y_iso = utils.get_y_hat(t_list_test.ravel(), s_iso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot PDF / calibration map / CDF for first 3 test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_list = t_list_test.copy()\n",
    "\n",
    "y = y_test.copy()\n",
    "\n",
    "t_list_mid = (t_list[0, 1:] + t_list[0, 0:-1]) / 2\n",
    "\n",
    "t_list = t_list.ravel()\n",
    "\n",
    "for i in numpy.random.permutation(numpy.arange(0, len(y)))[:3]:\n",
    "\n",
    "    fig, ax_list = matplotlib.pyplot.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    ax_list[2].plot(t_list, q_base[i, :], 'b', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[2].plot(t_list, q_iso[i, :], 'g', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[2].plot(t_list, q_gp[i, :], 'r', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[2].plot([y[i], y[i]], [0, 1], 'k--', linewidth=5, alpha=0.5)\n",
    "\n",
    "    ax_list[0].plot(t_list, s_base[i, :], 'b', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[0].plot(t_list_mid, s_iso[i, :], 'g', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[0].plot(t_list, s_gp[i, :], 'r', alpha=0.5, linewidth=5)\n",
    "\n",
    "    max_density = numpy.max(numpy.concatenate([s_base[i, :].ravel(), s_iso[i, :].ravel(), s_gp[i, :].ravel()]))\n",
    "\n",
    "    ax_list[0].plot([y[i], y[i]], [max_density, 0], 'k--', linewidth=5, alpha=0.5)\n",
    "\n",
    "    ax_list[0].set_title('PDF')\n",
    "\n",
    "    ax_list[1].plot(q_base[i, :], q_gp[i, :], 'r', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[1].plot(q_base[i, :], q_iso[i, :], 'g', alpha=0.5, linewidth=5)\n",
    "\n",
    "    ax_list[0].set_xlim([numpy.min(mu_cal) - numpy.max(sigma_cal), \n",
    "                         numpy.max(mu_cal) + numpy.max(sigma_cal)])\n",
    "    \n",
    "    ax_list[2].set_xlim([numpy.min(mu_cal) - numpy.max(sigma_cal), \n",
    "                         numpy.max(mu_cal) + numpy.max(sigma_cal)])\n",
    "\n",
    "    ax_list[1].set_xlim([0, 1])\n",
    "\n",
    "    ax_list[1].set_title('Calibration Map')\n",
    "\n",
    "    ax_list[2].set_title('CDF')\n",
    "\n",
    "    ax_list[2].legend(['base', 'isotonic', 'gp-beta', 'y'],\n",
    "                        bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    ax_list[0].grid(True)\n",
    "\n",
    "    ax_list[1].grid(True)\n",
    "\n",
    "    ax_list[2].grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate negative log-likelihood, pin-ball loss, and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9180782224430937, 3.1879355189242258, 2.749068434499746]\n"
     ]
    }
   ],
   "source": [
    "ll_base = - scipy.stats.norm.logpdf(y_test.reshape(-1, 1),\n",
    "                                    loc=mu_base.reshape(-1, 1),\n",
    "                                    scale=sigma_base.reshape(-1, 1)).ravel()\n",
    "ll_iso = utils.get_log_loss(y_test, t_list_test.ravel(), s_iso)\n",
    "ll_gp = utils.get_log_loss(y_test, t_list_test.ravel(), s_gp)\n",
    "print([numpy.mean(ll_base), numpy.mean(ll_iso), numpy.mean(ll_gp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156.23681995735856, 151.6178377176694, 145.12958346418304]\n"
     ]
    }
   ],
   "source": [
    "pbl_base = utils.get_pin_ball_loss(y_test, q_base, t_list_test.ravel())\n",
    "pbl_iso = utils.get_pin_ball_loss(y_test, q_iso, t_list_test.ravel())\n",
    "pbl_gp = utils.get_pin_ball_loss(y_test, q_gp, t_list_test.ravel())\n",
    "print([pbl_base[0], pbl_iso[0], pbl_gp[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.878142747595334, 19.82594643204267, 18.912419369113657]\n"
     ]
    }
   ],
   "source": [
    "se_base = utils.get_se(y_base, y_test)\n",
    "se_iso = utils.get_se(y_iso, y_test)\n",
    "se_gp = utils.get_se(y_gp, y_test)\n",
    "print([numpy.mean(se_base), numpy.mean(se_iso), numpy.mean(se_gp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
